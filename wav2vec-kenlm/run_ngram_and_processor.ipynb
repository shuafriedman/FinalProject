{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt install build-essential cmake libboost-system-dev libboost-thread-dev libboost-program-options-dev libboost-test-dev libeigen3-dev zlib1g-dev libbz2-dev liblzma-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd() +'/FinalProject/word2vec-kenlm/data/mesivta/'\n",
    "file = path + 'train.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before downloading and unpacking the KenLM repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-13 16:28:42--  https://kheafield.com/code/kenlm.tar.gz\n",
      "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
      "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 491888 (480K) [application/x-gzip]\n",
      "Saving to: ‚ÄòSTDOUT‚Äô\n",
      "\n",
      "-                   100%[===================>] 480.36K  2.11MB/s    in 0.2s    \n",
      "\n",
      "2024-03-13 16:28:42 (2.11 MB/s) - written to stdout [491888/491888]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import os\n",
    "\n",
    "if platform.system() == 'Darwin':  # Darwin stands for MacOS\n",
    "    !curl -L https://kheafield.com/code/kenlm.tar.gz | tar xz\n",
    "elif platform.system() == 'Linux':\n",
    "    !wget -O - https://kheafield.com/code/kenlm.tar.gz | tar xz\n",
    "else:\n",
    "    print(\"Unsupported operating system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KenLM is written in C++, so we'll make use of `cmake` to build the binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‚Äòkenlm/build‚Äô: File exists\n",
      "build_binary  fragment\t       lmplz\t\t\t     query\n",
      "count_ngrams  interpolate      phrase_table_vocab\t     streaming_example\n",
      "filter\t      kenlm_benchmark  probing_hash_table_benchmark\n"
     ]
    }
   ],
   "source": [
    "!mkdir kenlm/build && cd kenlm/build && cmake .. && make -j2\n",
    "!ls kenlm/build/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyctcdecode in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.15.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyctcdecode) (1.26.2)\n",
      "Requirement already satisfied: pygtrie<3.0,>=2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyctcdecode) (2.5.0)\n",
      "Requirement already satisfied: hypothesis<7,>=6.14 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyctcdecode) (6.97.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (1.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: kenlm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyctcdecode\n",
    "!pip install kenlm -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, as we can see, the executable functions have successfully been built under `kenlm/build/bin/`.\n",
    "\n",
    "KenLM by default computes an *n-gram* with [Kneser-Ney smooting](https://en.wikipedia.org/wiki/Kneser%E2%80%93Ney_smoothing). All text data used to create the *n-gram* is expected to be stored in a text file.\n",
    "We download our dataset and save it as a `.txt` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just have to run KenLM's `lmplz` command to build our *n-gram*, called `\"5gram.arpa\"`. As it's relatively common in speech recognition, we build a *5-gram* by passing the `-o 5` parameter.\n",
    "For more information on the different *n-gram* LM that can be built\n",
    "with KenLM, one can take a look at the [official website of KenLM](https://kheafield.com/code/kenlm/).\n",
    "\n",
    "Executing the command below might take a minute or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /teamspace/studios/this_studio/FinalProject/word2vec-kenlm/data/mesivta/train.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Unigram tokens 4989721 types 161274\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:1935288 2:1270423680 3:2382044672 4:3811271168 5:5558104064\n",
      "Statistics:\n",
      "1 161274 D1=0.592941 D2=1.05761 D3+=1.50101\n",
      "2 2136990 D1=0.784366 D2=1.17542 D3+=1.47568\n",
      "3 3902755 D1=0.90099 D2=1.34268 D3+=1.58097\n",
      "4 4541403 D1=0.956203 D2=1.50116 D3+=1.68527\n",
      "5 4760756 D1=0.95573 D2=1.51904 D3+=1.65912\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 327 assuming -p 1.5\n",
      "probing 389 assuming -r models -p 1.5\n",
      "trie    162 without quantization\n",
      "trie     90 assuming -q 8 -b 8 quantization \n",
      "trie    142 assuming -a 22 array pointer compression\n",
      "trie     70 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:1935288 2:34191840 3:78055100 4:108993672 5:133301168\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:1935288 2:34191840 3:78055100 4:108993672 5:133301168\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:12890788 kB\tVmRSS:10380 kB\tRSSMax:2399028 kB\tuser:17.6146\tsys:6.1779\tCPU:23.7926\treal:26.0555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!kenlm/build/bin/lmplz -o 5 <\"{file}\" > \"{path}/5gram.arpa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we have built a *5-gram* LM! Let's inspect the first couple of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\data\\\n",
      "ngram 1=161274\n",
      "ngram 2=2136990\n",
      "ngram 3=3902755\n",
      "ngram 4=4541403\n",
      "ngram 5=4760756\n",
      "\n",
      "\\1-grams:\n",
      "-6.3179564\t<unk>\t0\n",
      "0\t<s>\t-0.59340286\n",
      "-2.8985147\t</s>\t0\n",
      "-2.965528\t◊ï◊õ◊ü\t-0.4433093\n",
      "-3.892803\t◊§◊®◊ò\t-0.2773799\n",
      "-6.173038\t◊ú◊û◊°◊ï◊ú◊ô◊ù\t-0.10548098\n",
      "-2.976362\t◊©◊î◊ô◊ê\t-0.44526786\n",
      "-4.6349635\t◊†◊¢◊ú\t-0.17592013\n",
      "-2.783812\t◊©◊ê◊ô◊ü\t-0.5445806\n",
      "-2.757102\t◊ú◊ï\t-0.46461868\n",
      "-4.3451552\t◊¢◊ß◊ë\t-0.15198769\n",
      "-3.0338998\t◊©◊ê◊ô◊†◊ï\t-0.60274816\n"
     ]
    }
   ],
   "source": [
    "!head -20 {path}5gram.arpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a small problem that ü§ó Transformers will not be happy about later on.\n",
    "The *5-gram* correctly includes a \"Unknown\" or `<unk>`, as well as a *begin-of-sentence*, `<s>` token, but no *end-of-sentence*, `</s>` token.\n",
    "This sadly has to be corrected currently after the build.\n",
    "\n",
    "We can simply add the *end-of-sentence* token by adding the line `0 </s>  -0.11831701` below the *begin-of-sentence* token and increasing the `ngram 1` count by 1. Because the file has roughly 100 million lines, this command will take *ca.* 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path}5gram.arpa\", \"r\") as read_file, open(f\"{path}5gram_correct.arpa\", \"w\") as write_file:\n",
    "  has_added_eos = False\n",
    "  for line in read_file:\n",
    "    if not has_added_eos and \"ngram 1=\" in line:\n",
    "      count=line.strip().split(\"=\")[-1]\n",
    "      write_file.write(line.replace(f\"{count}\", f\"{int(count)+1}\"))\n",
    "    elif not has_added_eos and \"<s>\" in line:\n",
    "      write_file.write(line)\n",
    "      write_file.write(line.replace(\"<s>\", \"</s>\"))\n",
    "      has_added_eos = True\n",
    "    else:\n",
    "      write_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now inspect the corrected *5-gram*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\data\\\n",
      "ngram 1=161275\n",
      "ngram 2=2136990\n",
      "ngram 3=3902755\n",
      "ngram 4=4541403\n",
      "ngram 5=4760756\n",
      "\n",
      "\\1-grams:\n",
      "-6.3179564\t<unk>\t0\n",
      "0\t<s>\t-0.59340286\n",
      "0\t</s>\t-0.59340286\n",
      "-2.8985147\t</s>\t0\n",
      "-2.965528\t◊ï◊õ◊ü\t-0.4433093\n",
      "-3.892803\t◊§◊®◊ò\t-0.2773799\n",
      "-6.173038\t◊ú◊û◊°◊ï◊ú◊ô◊ù\t-0.10548098\n",
      "-2.976362\t◊©◊î◊ô◊ê\t-0.44526786\n",
      "-4.6349635\t◊†◊¢◊ú\t-0.17592013\n",
      "-2.783812\t◊©◊ê◊ô◊ü\t-0.5445806\n",
      "-2.757102\t◊ú◊ï\t-0.46461868\n",
      "-4.3451552\t◊¢◊ß◊ë\t-0.15198769\n"
     ]
    }
   ],
   "source": [
    "!head -20 {path}5gram_correct.arpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, this looks better! We're done at this point and all that is left to do is to correctly integrate the `\"ngram\"` with [`pyctcdecode`](https://github.com/kensho-technologies/pyctcdecode) and ü§ó Transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.auto because of the following error (look up to see its traceback):\ncannot import name 'is_g2p_en_available' from 'transformers.utils' (/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/import_utils.py:1382\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1381\u001b[0m     value = getattr(module, name)\n\u001b[0;32m-> 1382\u001b[0m else:\n\u001b[1;32m   1383\u001b[0m     raise AttributeError(f\"module {self.__name__} has no attribute {name}\")\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:992\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     albert,\n\u001b[1;32m     17\u001b[0m     align,\n\u001b[1;32m     18\u001b[0m     altclip,\n\u001b[1;32m     19\u001b[0m     audio_spectrogram_transformer,\n\u001b[1;32m     20\u001b[0m     auto,\n\u001b[1;32m     21\u001b[0m     autoformer,\n\u001b[1;32m     22\u001b[0m     bark,\n\u001b[1;32m     23\u001b[0m     bart,\n\u001b[1;32m     24\u001b[0m     barthez,\n\u001b[1;32m     25\u001b[0m     bartpho,\n\u001b[1;32m     26\u001b[0m     beit,\n\u001b[1;32m     27\u001b[0m     bert,\n\u001b[1;32m     28\u001b[0m     bert_generation,\n\u001b[1;32m     29\u001b[0m     bert_japanese,\n\u001b[1;32m     30\u001b[0m     bertweet,\n\u001b[1;32m     31\u001b[0m     big_bird,\n\u001b[1;32m     32\u001b[0m     bigbird_pegasus,\n\u001b[1;32m     33\u001b[0m     biogpt,\n\u001b[1;32m     34\u001b[0m     bit,\n\u001b[1;32m     35\u001b[0m     blenderbot,\n\u001b[1;32m     36\u001b[0m     blenderbot_small,\n\u001b[1;32m     37\u001b[0m     blip,\n\u001b[1;32m     38\u001b[0m     blip_2,\n\u001b[1;32m     39\u001b[0m     bloom,\n\u001b[1;32m     40\u001b[0m     bridgetower,\n\u001b[1;32m     41\u001b[0m     bros,\n\u001b[1;32m     42\u001b[0m     byt5,\n\u001b[1;32m     43\u001b[0m     camembert,\n\u001b[1;32m     44\u001b[0m     canine,\n\u001b[1;32m     45\u001b[0m     chinese_clip,\n\u001b[1;32m     46\u001b[0m     clap,\n\u001b[1;32m     47\u001b[0m     clip,\n\u001b[1;32m     48\u001b[0m     clipseg,\n\u001b[1;32m     49\u001b[0m     clvp,\n\u001b[1;32m     50\u001b[0m     code_llama,\n\u001b[1;32m     51\u001b[0m     codegen,\n\u001b[1;32m     52\u001b[0m     conditional_detr,\n\u001b[1;32m     53\u001b[0m     convbert,\n\u001b[1;32m     54\u001b[0m     convnext,\n\u001b[1;32m     55\u001b[0m     convnextv2,\n\u001b[1;32m     56\u001b[0m     cpm,\n\u001b[1;32m     57\u001b[0m     cpmant,\n\u001b[1;32m     58\u001b[0m     ctrl,\n\u001b[1;32m     59\u001b[0m     cvt,\n\u001b[1;32m     60\u001b[0m     data2vec,\n\u001b[1;32m     61\u001b[0m     deberta,\n\u001b[1;32m     62\u001b[0m     deberta_v2,\n\u001b[1;32m     63\u001b[0m     decision_transformer,\n\u001b[1;32m     64\u001b[0m     deformable_detr,\n\u001b[1;32m     65\u001b[0m     deit,\n\u001b[1;32m     66\u001b[0m     deprecated,\n\u001b[1;32m     67\u001b[0m     depth_anything,\n\u001b[1;32m     68\u001b[0m     deta,\n\u001b[1;32m     69\u001b[0m     detr,\n\u001b[1;32m     70\u001b[0m     dialogpt,\n\u001b[1;32m     71\u001b[0m     dinat,\n\u001b[1;32m     72\u001b[0m     dinov2,\n\u001b[1;32m     73\u001b[0m     distilbert,\n\u001b[1;32m     74\u001b[0m     dit,\n\u001b[1;32m     75\u001b[0m     donut,\n\u001b[1;32m     76\u001b[0m     dpr,\n\u001b[1;32m     77\u001b[0m     dpt,\n\u001b[1;32m     78\u001b[0m     efficientformer,\n\u001b[1;32m     79\u001b[0m     efficientnet,\n\u001b[1;32m     80\u001b[0m     electra,\n\u001b[1;32m     81\u001b[0m     encodec,\n\u001b[1;32m     82\u001b[0m     encoder_decoder,\n\u001b[1;32m     83\u001b[0m     ernie,\n\u001b[1;32m     84\u001b[0m     ernie_m,\n\u001b[1;32m     85\u001b[0m     esm,\n\u001b[1;32m     86\u001b[0m     falcon,\n\u001b[1;32m     87\u001b[0m     fastspeech2_conformer,\n\u001b[1;32m     88\u001b[0m     flaubert,\n\u001b[1;32m     89\u001b[0m     flava,\n\u001b[1;32m     90\u001b[0m     fnet,\n\u001b[1;32m     91\u001b[0m     focalnet,\n\u001b[1;32m     92\u001b[0m     fsmt,\n\u001b[1;32m     93\u001b[0m     funnel,\n\u001b[1;32m     94\u001b[0m     fuyu,\n\u001b[1;32m     95\u001b[0m     gemma,\n\u001b[1;32m     96\u001b[0m     git,\n\u001b[1;32m     97\u001b[0m     glpn,\n\u001b[1;32m     98\u001b[0m     gpt2,\n\u001b[1;32m     99\u001b[0m     gpt_bigcode,\n\u001b[1;32m    100\u001b[0m     gpt_neo,\n\u001b[1;32m    101\u001b[0m     gpt_neox,\n\u001b[1;32m    102\u001b[0m     gpt_neox_japanese,\n\u001b[1;32m    103\u001b[0m     gpt_sw3,\n\u001b[1;32m    104\u001b[0m     gptj,\n\u001b[1;32m    105\u001b[0m     gptsan_japanese,\n\u001b[1;32m    106\u001b[0m     graphormer,\n\u001b[1;32m    107\u001b[0m     groupvit,\n\u001b[1;32m    108\u001b[0m     herbert,\n\u001b[1;32m    109\u001b[0m     hubert,\n\u001b[1;32m    110\u001b[0m     ibert,\n\u001b[1;32m    111\u001b[0m     idefics,\n\u001b[1;32m    112\u001b[0m     imagegpt,\n\u001b[1;32m    113\u001b[0m     informer,\n\u001b[1;32m    114\u001b[0m     instructblip,\n\u001b[1;32m    115\u001b[0m     jukebox,\n\u001b[1;32m    116\u001b[0m     kosmos2,\n\u001b[1;32m    117\u001b[0m     layoutlm,\n\u001b[1;32m    118\u001b[0m     layoutlmv2,\n\u001b[1;32m    119\u001b[0m     layoutlmv3,\n\u001b[1;32m    120\u001b[0m     layoutxlm,\n\u001b[1;32m    121\u001b[0m     led,\n\u001b[1;32m    122\u001b[0m     levit,\n\u001b[1;32m    123\u001b[0m     lilt,\n\u001b[1;32m    124\u001b[0m     llama,\n\u001b[1;32m    125\u001b[0m     llava,\n\u001b[1;32m    126\u001b[0m     longformer,\n\u001b[1;32m    127\u001b[0m     longt5,\n\u001b[1;32m    128\u001b[0m     luke,\n\u001b[1;32m    129\u001b[0m     lxmert,\n\u001b[1;32m    130\u001b[0m     m2m_100,\n\u001b[1;32m    131\u001b[0m     marian,\n\u001b[1;32m    132\u001b[0m     markuplm,\n\u001b[1;32m    133\u001b[0m     mask2former,\n\u001b[1;32m    134\u001b[0m     maskformer,\n\u001b[1;32m    135\u001b[0m     mbart,\n\u001b[1;32m    136\u001b[0m     mbart50,\n\u001b[1;32m    137\u001b[0m     mega,\n\u001b[1;32m    138\u001b[0m     megatron_bert,\n\u001b[1;32m    139\u001b[0m     megatron_gpt2,\n\u001b[1;32m    140\u001b[0m     mgp_str,\n\u001b[1;32m    141\u001b[0m     mistral,\n\u001b[1;32m    142\u001b[0m     mixtral,\n\u001b[1;32m    143\u001b[0m     mluke,\n\u001b[1;32m    144\u001b[0m     mobilebert,\n\u001b[1;32m    145\u001b[0m     mobilenet_v1,\n\u001b[1;32m    146\u001b[0m     mobilenet_v2,\n\u001b[1;32m    147\u001b[0m     mobilevit,\n\u001b[1;32m    148\u001b[0m     mobilevitv2,\n\u001b[1;32m    149\u001b[0m     mpnet,\n\u001b[1;32m    150\u001b[0m     mpt,\n\u001b[1;32m    151\u001b[0m     mra,\n\u001b[1;32m    152\u001b[0m     mt5,\n\u001b[1;32m    153\u001b[0m     musicgen,\n\u001b[1;32m    154\u001b[0m     mvp,\n\u001b[1;32m    155\u001b[0m     nat,\n\u001b[1;32m    156\u001b[0m     nezha,\n\u001b[1;32m    157\u001b[0m     nllb,\n\u001b[1;32m    158\u001b[0m     nllb_moe,\n\u001b[1;32m    159\u001b[0m     nougat,\n\u001b[1;32m    160\u001b[0m     nystromformer,\n\u001b[1;32m    161\u001b[0m     oneformer,\n\u001b[1;32m    162\u001b[0m     openai,\n\u001b[1;32m    163\u001b[0m     opt,\n\u001b[1;32m    164\u001b[0m     owlv2,\n\u001b[1;32m    165\u001b[0m     owlvit,\n\u001b[1;32m    166\u001b[0m     patchtsmixer,\n\u001b[1;32m    167\u001b[0m     patchtst,\n\u001b[1;32m    168\u001b[0m     pegasus,\n\u001b[1;32m    169\u001b[0m     pegasus_x,\n\u001b[1;32m    170\u001b[0m     perceiver,\n\u001b[1;32m    171\u001b[0m     persimmon,\n\u001b[1;32m    172\u001b[0m     phi,\n\u001b[1;32m    173\u001b[0m     phobert,\n\u001b[1;32m    174\u001b[0m     pix2struct,\n\u001b[1;32m    175\u001b[0m     plbart,\n\u001b[1;32m    176\u001b[0m     poolformer,\n\u001b[1;32m    177\u001b[0m     pop2piano,\n\u001b[1;32m    178\u001b[0m     prophetnet,\n\u001b[1;32m    179\u001b[0m     pvt,\n\u001b[1;32m    180\u001b[0m     qdqbert,\n\u001b[1;32m    181\u001b[0m     qwen2,\n\u001b[1;32m    182\u001b[0m     rag,\n\u001b[1;32m    183\u001b[0m     realm,\n\u001b[1;32m    184\u001b[0m     reformer,\n\u001b[1;32m    185\u001b[0m     regnet,\n\u001b[1;32m    186\u001b[0m     rembert,\n\u001b[1;32m    187\u001b[0m     resnet,\n\u001b[1;32m    188\u001b[0m     roberta,\n\u001b[1;32m    189\u001b[0m     roberta_prelayernorm,\n\u001b[1;32m    190\u001b[0m     roc_bert,\n\u001b[1;32m    191\u001b[0m     roformer,\n\u001b[1;32m    192\u001b[0m     rwkv,\n\u001b[1;32m    193\u001b[0m     sam,\n\u001b[1;32m    194\u001b[0m     seamless_m4t,\n\u001b[1;32m    195\u001b[0m     seamless_m4t_v2,\n\u001b[1;32m    196\u001b[0m     segformer,\n\u001b[1;32m    197\u001b[0m     sew,\n\u001b[1;32m    198\u001b[0m     sew_d,\n\u001b[1;32m    199\u001b[0m     siglip,\n\u001b[1;32m    200\u001b[0m     speech_encoder_decoder,\n\u001b[1;32m    201\u001b[0m     speech_to_text,\n\u001b[1;32m    202\u001b[0m     speech_to_text_2,\n\u001b[1;32m    203\u001b[0m     speecht5,\n\u001b[1;32m    204\u001b[0m     splinter,\n\u001b[1;32m    205\u001b[0m     squeezebert,\n\u001b[1;32m    206\u001b[0m     stablelm,\n\u001b[1;32m    207\u001b[0m     swiftformer,\n\u001b[1;32m    208\u001b[0m     swin,\n\u001b[1;32m    209\u001b[0m     swin2sr,\n\u001b[1;32m    210\u001b[0m     swinv2,\n\u001b[1;32m    211\u001b[0m     switch_transformers,\n\u001b[1;32m    212\u001b[0m     t5,\n\u001b[1;32m    213\u001b[0m     table_transformer,\n\u001b[1;32m    214\u001b[0m     tapas,\n\u001b[1;32m    215\u001b[0m     time_series_transformer,\n\u001b[1;32m    216\u001b[0m     timesformer,\n\u001b[1;32m    217\u001b[0m     timm_backbone,\n\u001b[1;32m    218\u001b[0m     trocr,\n\u001b[1;32m    219\u001b[0m     tvlt,\n\u001b[1;32m    220\u001b[0m     tvp,\n\u001b[1;32m    221\u001b[0m     umt5,\n\u001b[1;32m    222\u001b[0m     unispeech,\n\u001b[1;32m    223\u001b[0m     unispeech_sat,\n\u001b[1;32m    224\u001b[0m     univnet,\n\u001b[1;32m    225\u001b[0m     upernet,\n\u001b[1;32m    226\u001b[0m     videomae,\n\u001b[1;32m    227\u001b[0m     vilt,\n\u001b[1;32m    228\u001b[0m     vipllava,\n\u001b[1;32m    229\u001b[0m     vision_encoder_decoder,\n\u001b[1;32m    230\u001b[0m     vision_text_dual_encoder,\n\u001b[1;32m    231\u001b[0m     visual_bert,\n\u001b[1;32m    232\u001b[0m     vit,\n\u001b[1;32m    233\u001b[0m     vit_hybrid,\n\u001b[1;32m    234\u001b[0m     vit_mae,\n\u001b[1;32m    235\u001b[0m     vit_msn,\n\u001b[1;32m    236\u001b[0m     vitdet,\n\u001b[1;32m    237\u001b[0m     vitmatte,\n\u001b[1;32m    238\u001b[0m     vits,\n\u001b[1;32m    239\u001b[0m     vivit,\n\u001b[1;32m    240\u001b[0m     wav2vec2,\n\u001b[1;32m    241\u001b[0m     wav2vec2_bert,\n\u001b[1;32m    242\u001b[0m     wav2vec2_conformer,\n\u001b[1;32m    243\u001b[0m     wav2vec2_phoneme,\n\u001b[1;32m    244\u001b[0m     wav2vec2_with_lm,\n\u001b[1;32m    245\u001b[0m     wavlm,\n\u001b[1;32m    246\u001b[0m     whisper,\n\u001b[1;32m    247\u001b[0m     x_clip,\n\u001b[1;32m    248\u001b[0m     xglm,\n\u001b[1;32m    249\u001b[0m     xlm,\n\u001b[1;32m    250\u001b[0m     xlm_prophetnet,\n\u001b[1;32m    251\u001b[0m     xlm_roberta,\n\u001b[1;32m    252\u001b[0m     xlm_roberta_xl,\n\u001b[1;32m    253\u001b[0m     xlnet,\n\u001b[1;32m    254\u001b[0m     xmod,\n\u001b[1;32m    255\u001b[0m     yolos,\n\u001b[1;32m    256\u001b[0m     yoso,\n\u001b[1;32m    257\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/depth_anything/__init__.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfile_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m _LazyModule, is_torch_available\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m OptionalDependencyNotAvailable\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/file_utils.py:26\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m# Backward compatibility imports, to make sure all those objects can be found in file_utils\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     28\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     29\u001b[0m     DUMMY_INPUTS,\n\u001b[1;32m     30\u001b[0m     DUMMY_MASK,\n\u001b[1;32m     31\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m     32\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[1;32m     33\u001b[0m     FEATURE_EXTRACTOR_NAME,\n\u001b[1;32m     34\u001b[0m     FLAX_WEIGHTS_NAME,\n\u001b[1;32m     35\u001b[0m     HF_MODULES_CACHE,\n\u001b[1;32m     36\u001b[0m     HUGGINGFACE_CO_PREFIX,\n\u001b[1;32m     37\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[1;32m     38\u001b[0m     MODEL_CARD_NAME,\n\u001b[1;32m     39\u001b[0m     MULTIPLE_CHOICE_DUMMY_INPUTS,\n\u001b[1;32m     40\u001b[0m     PYTORCH_PRETRAINED_BERT_CACHE,\n\u001b[1;32m     41\u001b[0m     PYTORCH_TRANSFORMERS_CACHE,\n\u001b[1;32m     42\u001b[0m     S3_BUCKET_PREFIX,\n\u001b[1;32m     43\u001b[0m     SENTENCEPIECE_UNDERLINE,\n\u001b[1;32m     44\u001b[0m     SPIECE_UNDERLINE,\n\u001b[1;32m     45\u001b[0m     TF2_WEIGHTS_NAME,\n\u001b[1;32m     46\u001b[0m     TF_WEIGHTS_NAME,\n\u001b[1;32m     47\u001b[0m     TORCH_FX_REQUIRED_VERSION,\n\u001b[1;32m     48\u001b[0m     TRANSFORMERS_CACHE,\n\u001b[1;32m     49\u001b[0m     TRANSFORMERS_DYNAMIC_MODULE_NAME,\n\u001b[1;32m     50\u001b[0m     USE_JAX,\n\u001b[1;32m     51\u001b[0m     USE_TF,\n\u001b[1;32m     52\u001b[0m     USE_TORCH,\n\u001b[1;32m     53\u001b[0m     WEIGHTS_INDEX_NAME,\n\u001b[1;32m     54\u001b[0m     WEIGHTS_NAME,\n\u001b[1;32m     55\u001b[0m     ContextManagers,\n\u001b[1;32m     56\u001b[0m     DummyObject,\n\u001b[1;32m     57\u001b[0m     EntryNotFoundError,\n\u001b[1;32m     58\u001b[0m     ExplicitEnum,\n\u001b[1;32m     59\u001b[0m     ModelOutput,\n\u001b[1;32m     60\u001b[0m     PaddingStrategy,\n\u001b[1;32m     61\u001b[0m     PushToHubMixin,\n\u001b[1;32m     62\u001b[0m     RepositoryNotFoundError,\n\u001b[1;32m     63\u001b[0m     RevisionNotFoundError,\n\u001b[1;32m     64\u001b[0m     TensorType,\n\u001b[1;32m     65\u001b[0m     _LazyModule,\n\u001b[1;32m     66\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     67\u001b[0m     add_end_docstrings,\n\u001b[1;32m     68\u001b[0m     add_start_docstrings,\n\u001b[1;32m     69\u001b[0m     add_start_docstrings_to_model_forward,\n\u001b[1;32m     70\u001b[0m     cached_property,\n\u001b[1;32m     71\u001b[0m     copy_func,\n\u001b[1;32m     72\u001b[0m     default_cache_path,\n\u001b[1;32m     73\u001b[0m     define_sagemaker_information,\n\u001b[1;32m     74\u001b[0m     get_cached_models,\n\u001b[1;32m     75\u001b[0m     get_file_from_repo,\n\u001b[1;32m     76\u001b[0m     get_torch_version,\n\u001b[1;32m     77\u001b[0m     has_file,\n\u001b[1;32m     78\u001b[0m     http_user_agent,\n\u001b[1;32m     79\u001b[0m     is_apex_available,\n\u001b[1;32m     80\u001b[0m     is_bs4_available,\n\u001b[1;32m     81\u001b[0m     is_coloredlogs_available,\n\u001b[1;32m     82\u001b[0m     is_datasets_available,\n\u001b[1;32m     83\u001b[0m     is_detectron2_available,\n\u001b[1;32m     84\u001b[0m     is_faiss_available,\n\u001b[1;32m     85\u001b[0m     is_flax_available,\n\u001b[1;32m     86\u001b[0m     is_ftfy_available,\n\u001b[1;32m     87\u001b[0m     is_g2p_en_available,\n\u001b[1;32m     88\u001b[0m     is_in_notebook,\n\u001b[1;32m     89\u001b[0m     is_ipex_available,\n\u001b[1;32m     90\u001b[0m     is_librosa_available,\n\u001b[1;32m     91\u001b[0m     is_offline_mode,\n\u001b[1;32m     92\u001b[0m     is_onnx_available,\n\u001b[1;32m     93\u001b[0m     is_pandas_available,\n\u001b[1;32m     94\u001b[0m     is_phonemizer_available,\n\u001b[1;32m     95\u001b[0m     is_protobuf_available,\n\u001b[1;32m     96\u001b[0m     is_psutil_available,\n\u001b[1;32m     97\u001b[0m     is_py3nvml_available,\n\u001b[1;32m     98\u001b[0m     is_pyctcdecode_available,\n\u001b[1;32m     99\u001b[0m     is_pytesseract_available,\n\u001b[1;32m    100\u001b[0m     is_pytorch_quantization_available,\n\u001b[1;32m    101\u001b[0m     is_rjieba_available,\n\u001b[1;32m    102\u001b[0m     is_sagemaker_dp_enabled,\n\u001b[1;32m    103\u001b[0m     is_sagemaker_mp_enabled,\n\u001b[1;32m    104\u001b[0m     is_scipy_available,\n\u001b[1;32m    105\u001b[0m     is_sentencepiece_available,\n\u001b[1;32m    106\u001b[0m     is_seqio_available,\n\u001b[1;32m    107\u001b[0m     is_sklearn_available,\n\u001b[1;32m    108\u001b[0m     is_soundfile_availble,\n\u001b[1;32m    109\u001b[0m     is_spacy_available,\n\u001b[1;32m    110\u001b[0m     is_speech_available,\n\u001b[1;32m    111\u001b[0m     is_tensor,\n\u001b[1;32m    112\u001b[0m     is_tensorflow_probability_available,\n\u001b[1;32m    113\u001b[0m     is_tf2onnx_available,\n\u001b[1;32m    114\u001b[0m     is_tf_available,\n\u001b[1;32m    115\u001b[0m     is_timm_available,\n\u001b[1;32m    116\u001b[0m     is_tokenizers_available,\n\u001b[1;32m    117\u001b[0m     is_torch_available,\n\u001b[1;32m    118\u001b[0m     is_torch_bf16_available,\n\u001b[1;32m    119\u001b[0m     is_torch_cuda_available,\n\u001b[1;32m    120\u001b[0m     is_torch_fx_available,\n\u001b[1;32m    121\u001b[0m     is_torch_fx_proxy,\n\u001b[1;32m    122\u001b[0m     is_torch_mps_available,\n\u001b[1;32m    123\u001b[0m     is_torch_tf32_available,\n\u001b[1;32m    124\u001b[0m     is_torch_tpu_available,\n\u001b[1;32m    125\u001b[0m     is_torchaudio_available,\n\u001b[1;32m    126\u001b[0m     is_training_run_on_sagemaker,\n\u001b[1;32m    127\u001b[0m     is_vision_available,\n\u001b[1;32m    128\u001b[0m     replace_return_docstrings,\n\u001b[1;32m    129\u001b[0m     requires_backends,\n\u001b[1;32m    130\u001b[0m     to_numpy,\n\u001b[1;32m    131\u001b[0m     to_py_obj,\n\u001b[1;32m    132\u001b[0m     torch_only_method,\n\u001b[1;32m    133\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_g2p_en_available' from 'transformers.utils' (/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/teamspace/studios/this_studio/FinalProject/word2vec-kenlm/run_ngram_and_processor.ipynb Cell 22\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-01hrmwnnhcqaxrcacfvrphtn31.studio.lightning.ai/teamspace/studios/this_studio/FinalProject/word2vec-kenlm/run_ngram_and_processor.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# from transformers import AutoProcessor\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-01hrmwnnhcqaxrcacfvrphtn31.studio.lightning.ai/teamspace/studios/this_studio/FinalProject/word2vec-kenlm/run_ngram_and_processor.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-01hrmwnnhcqaxrcacfvrphtn31.studio.lightning.ai/teamspace/studios/this_studio/FinalProject/word2vec-kenlm/run_ngram_and_processor.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# processor = AutoProcessor.from_pretrained(\"imvladikon/wav2vec2-xls-r-300m-hebrew\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://vscode-01hrmwnnhcqaxrcacfvrphtn31.studio.lightning.ai/teamspace/studios/this_studio/FinalProject/word2vec-kenlm/run_ngram_and_processor.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoProcessor\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/import_utils.py:1372\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[39mif\u001b[39;00m attr \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m result:\n\u001b[1;32m   1371\u001b[0m         result\u001b[39m.\u001b[39mappend(attr)\n\u001b[0;32m-> 1372\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/import_utils.py:1384\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.auto because of the following error (look up to see its traceback):\ncannot import name 'is_g2p_en_available' from 'transformers.utils' (/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoProcessor\n",
    "\n",
    "# processor = AutoProcessor.from_pretrained(\"imvladikon/wav2vec2-xls-r-300m-hebrew\")\n",
    "from transformers import AutoProcessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract the vocabulary of its tokenizer as it represents the `\"labels\"` of `pyctcdecode`'s `BeamSearchDecoder` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `\"labels\"` and the previously built `5gram_correct.arpa` file is all that's needed to build the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /teamspace/studios/this_studio/FinalProject/word2vec-kenlm/data/mesivta/5gram_correct.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "Unigrams and labels don't seem to agree.\n"
     ]
    }
   ],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "\n",
    "decoder = build_ctcdecoder(\n",
    "    labels=list(sorted_vocab_dict.keys()),\n",
    "    kenlm_model_path=f\"{path}5gram_correct.arpa\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can safely ignore the warning and all that is left to do now is to wrap the just created `decoder`, together with the processor's `tokenizer` and `feature_extractor` into a `Wav2Vec2ProcessorWithLM` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ProcessorWithLM\n",
    "\n",
    "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    decoder=decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to directly upload the LM-boosted processor into\n",
    "the model folder of [`xls-r-300m-sv`](https://huggingface.co/hf-test/xls-r-300m-sv) to have all relevant files in one place.\n",
    "\n",
    "Let's clone the repo, add the new decoder files and upload them afterward.\n",
    "First, we need to install `git-lfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git-lfs is already the newest version (2.9.2-1).\n",
      "The following NEW packages will be installed:\n",
      "  tree\n",
      "0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 43.0 kB of archives.\n",
      "After this operation, 115 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tree amd64 1.8.0-1 [43.0 kB]\n",
      "Fetched 43.0 kB in 0s (295 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package tree.\n",
      "(Reading database ... 82245 files and directories currently installed.)\n",
      "Preparing to unpack .../tree_1.8.0-1_amd64.deb ...\n",
      "Unpacking tree (1.8.0-1) ...\n",
      "Setting up tree (1.8.0-1) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install git-lfs tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloning and uploading of modeling files can be done conveniently with the `huggingface_hub`'s `Repository` class.\n",
    "\n",
    "More information on how to use the `huggingface_hub` to upload any files, please take a look at the [official docs](https://huggingface.co/docs/hub/how-to-upstream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Cloning https://huggingface.co/imvladikon/wav2vec2-xls-r-300m-hebrew into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a5fe324339495aa35825f729e77a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 32.0k/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8eaaf87e50419cb04c5e2d6eede3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin: 100%|##########| 2.98k/2.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87558133ef449d092728aa766c5b8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  34%|###3      | 1.00k/2.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bee8df986b1472da4431ed320e0d433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file model.safetensors:   0%|          | 1.40k/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b4d13c02814d4d9796b327ff6a1786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e2db8538614cf89daaffa6bd8f5c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file model.safetensors:   0%|          | 1.00k/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from huggingface_hub import Repository\n",
    "\n",
    "# repo = Repository(local_dir=\"FinalProject/models/ken-lm\", clone_from=\"imvladikon/wav2vec2-xls-r-300m-hebrew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having cloned `xls-r-300m-sv`, let's save the new processor with LM into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor_with_lm.save_pretrained(\"xls-r-300m-sv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the local repository. The `tree` command conveniently can also show the size of the different files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tree -h xls-r-300m-sv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen the *5-gram* LM is quite large - it amounts to more than 4 GB.\n",
    "To reduce the size of the *n-gram* and make loading faster, `kenLM` allows converting `.arpa` files to binary ones using the `build_binary` executable.\n",
    "\n",
    "Let's make use of it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kenlm/build/bin/build_binary xls-r-300m-sv/language_model/5gram_correct.arpa xls-r-300m-sv/language_model/5gram.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, it worked! Let's remove the `.arpa` file and check the size of the binary *5-gram* LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm xls-r-300m-sv/language_model/5gram_correct.arpa && tree -h xls-r-300m-sv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, we reduced the *n-gram* by more than half to less than 2GB now. In the final step, let's upload all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo.push_to_hub(commit_message=\"Upload lm-boosted decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the processor to local\n",
    "processor_with_lm.save_pretrained(\"/teamspace/studios/this_studio/FinalProject/models/KenLM-Wav2Vec2-Hebrew-Mesivta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
