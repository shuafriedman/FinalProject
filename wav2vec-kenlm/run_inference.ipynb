{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Combine an *n-gram* with Wav2Vec2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a final step, we want to wrap the *5-gram* into a `Wav2Vec2ProcessorWithLM` object to make the *5-gram* boosted decoding as seamless as shown in Section 1.\n",
    "We start by downloading the currently \"LM-less\" processor of [`xls-r-300m-sv`](https://huggingface.co/hf-test/xls-r-300m-sv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  libgles2 libopengl0 nsight-compute-2023.1.0\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run inference on test dataset first example\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "from transformers import Wav2Vec2CTCTokenizer, SeamlessM4TFeatureExtractor, Wav2Vec2BertForCTC, Wav2Vec2ProcessorWithLM, Wav2Vec2BertProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.25.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first 10 seconds of the audio\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "\n",
    "import math\n",
    "\n",
    "# Load your MP3 file\n",
    "audio = AudioSegment.from_mp3(\"FinalProject/wav2vec-kenlm/data/dafyomi/batra_155.mp3\")\n",
    "\n",
    "# Define the length of each chunk in milliseconds\n",
    "chunk_length_ms = 10000  # 10 seconds * 1000 ms/sec\n",
    "chunks = make_chunks(audio, chunk_length_ms) \n",
    "chunks = [chunk.set_frame_rate(16000).set_channels(1) for chunk in chunks]\n",
    "chunks = [np.array(chunk.get_array_of_samples()) for chunk in chunks]\n",
    "chunks = [chunk.astype(np.float32) / np.abs(chunk).max() for chunk in chunks]\n",
    "# Calculate the number of chunks to split the file into\n",
    "# num_chunks = math.ceil(len(audio) / chunk_length_ms)\n",
    "# chunks = []\n",
    "# Split the audio and save each chunk\n",
    "# for i in range(num_chunks):\n",
    "#     start_ms = i * chunk_length_ms\n",
    "#     end_ms = min((i + 1) * chunk_length_ms, len(audio))\n",
    "#     chunk = audio[start_ms:end_ms]\n",
    "#     chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "\n",
    "class ASRModel:\n",
    "    def __init__(self, model_name=None, model=None, processor=None, feature_extractor=None, tokenizer=None, lm_model=False):\n",
    "        self.model_name=model_name\n",
    "        self.feature_extractor=feature_extractor\n",
    "        self.processor=processor\n",
    "        self.tokenizer=tokenizer\n",
    "        self.lm_model=lm_model\n",
    "        if feature_extractor and tokenizer:\n",
    "            self.feature_extractor=feature_extractor\n",
    "            self.tokenizer=tokenizer\n",
    "            self.processor=AutoProcessor(feature_extractor=feature_extractor, processor=processor)\n",
    "\n",
    "        elif processor:\n",
    "            self.processor=processor\n",
    "        else:\n",
    "            self.processor = AutoProcessor.from_pretrained(model_name)\n",
    "        \n",
    "        print('Getting Model...')\n",
    "        if lm_model:\n",
    "            self.model= AutoModelForCTC.from_pretrained(model_name)\n",
    "        elif model:\n",
    "           self.model=model \n",
    "        else:\n",
    "            self.model = AutoModelForCTC.from_pretrained(model_name)\n",
    "\n",
    "            \n",
    "    def get_prediction(self, inputs, sampling_rate=16000, return_tensors=\"pt\"):\n",
    "        self.inputs= self.processor(inputs, sampling_rate=sampling_rate, return_tensors=return_tensors)\n",
    "        with torch.no_grad():\n",
    "            self.logits = self.model(**self.inputs).logits\n",
    "        if self.lm_model:\n",
    "            return self.lm_model.batch_decode(self.logits.numpy()).text\n",
    "        else:\n",
    "            predicted_ids = torch.argmax(self.logits, dim=-1)\n",
    "            return self.processor.batch_decode(predicted_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = chunks[9]\n",
    "sf.write(\"bert_test.wav\", sample, 16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /teamspace/studios/this_studio/FinalProject/models/KenLM-Wav2Vec2-Hebrew-Mesivta/language_model/5gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Model...\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2BertProcessor.from_pretrained('models/facebook/w2v-bert-2.0-finetuned', \n",
    "                                            unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "\n",
    "bertLM = Wav2Vec2ProcessorWithLM.from_pretrained(\"/teamspace/studios/this_studio/FinalProject/models/KenLM-Wav2Vec2-Hebrew-Mesivta\")\n",
    "wav2vec2BertLm = ASRModel(model_name=\"models/facebook/w2v-bert-2.0-finetuned\", processor=processor, lm_model=bertLM)\n",
    "# sample = chunks[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ה עשרה ושתיסרות אבל אם הגיל הוא גיל עשרים אז מגיל עשרים שתי סערות כבר לא משנים כי הרי יש משנה בנידה שאומרת שמי שלא הביא שתי צרות עד גיל עשרים זה אומר שהוא צר']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = processor(sample, sampling_rate=16000, return_tensors=\"pt\")\n",
    "wav2vec2BertLm.get_prediction(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /teamspace/studios/this_studio/FinalProject/models/KenLM-Wav2Vec2-imvladikon-300m/language_model/5gram_correct.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at imvladikon/wav2vec2-xls-r-300m-hebrew were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at imvladikon/wav2vec2-xls-r-300m-hebrew and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/teamspace/studios/this_studio/FinalProject/wav2vec-kenlm/run_inference.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-01hrmwnnhcqaxrcacfvrphtn31.studio.lightning.ai/teamspace/studios/this_studio/FinalProject/wav2vec-kenlm/run_inference.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m lm \u001b[39m=\u001b[39m Wav2Vec2ProcessorWithLM\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39m/teamspace/studios/this_studio/FinalProject/models/KenLM-Wav2Vec2-imvladikon-300m\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-01hrmwnnhcqaxrcacfvrphtn31.studio.lightning.ai/teamspace/studios/this_studio/FinalProject/wav2vec-kenlm/run_inference.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m wav2vec_he_lm \u001b[39m=\u001b[39m ASRModel(\u001b[39m\"\u001b[39m\u001b[39mimvladikon/wav2vec2-xls-r-300m-hebrew\u001b[39m\u001b[39m\"\u001b[39m, lm_model\u001b[39m=\u001b[39mlm)\n\u001b[0;32m----> <a href='vscode-notebook-cell://vscode-01hrmwnnhcqaxrcacfvrphtn31.studio.lightning.ai/teamspace/studios/this_studio/FinalProject/wav2vec-kenlm/run_inference.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m wav2vec_he_lm\u001b[39m.\u001b[39mget_prediction(sample)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "lm = Wav2Vec2ProcessorWithLM.from_pretrained(\"/teamspace/studios/this_studio/FinalProject/models/KenLM-Wav2Vec2-imvladikon-300m\")\n",
    "wav2vec_he_lm = ASRModel(\"imvladikon/wav2vec2-xls-r-300m-hebrew\", lm_model=lm)\n",
    "# wav2vec_he_lm.get_prediction(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Sample 0\n",
      "Bert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['שלום לכולם אנו למדים בדף קוף נון הי מסכת במטרה באתר סיני נקודה אוארגינקודה האל דף עמי של עשר דקות אנחנו מתחילים קצת מעל אמצע העמוד הזכרנו בדף הקודם א']\n",
      "Imvladikon\n",
      "['שלו לכולם אנחנו עומדים מתכוונים מסברא נור⁇דשלרקות אנחנו מקצתו הזכרנו בדף הקודם']\n",
      "For Sample 1\n",
      "Bert\n",
      "['את המעשה שקרה בבני ברק שאחד יירש נכסים ומחר אותם לאחרים והיורשים של אותו נוטן טענו שכשהוא נתן הוא היה קטן הזברנו שלא מדובר בממשק']\n",
      "Imvladikon\n",
      "['מעשה שקרא בבני ברק שאחד ירא נכסים ומכר אותם לאחרים יורשים שנותנות תנו שכשהוא ננוה קטן וסברנו שלא מדובר במשקה']\n",
      "For Sample 2\n",
      "Bert\n",
      "['ן אלה הוא היה אפילו בן שמונה עשרה או בין עשרים כמו שעוד רגע נראה אבל עוד א היו לו שתיסערות שזה מראה על בגרות ולכן הוא אהיה יכול למקור אז אתמול זכרנו את נושא זה בקצרה ה']\n",
      "Imvladikon\n",
      "['אלא ו היה אפילו בן נסוב כמו שעות ונראה אבל לא לא היו לו שתי שרות שמערות ולכן לא היה יכול זה ולקנות נושא זה בקצרה']\n",
      "For Sample 3\n",
      "Bert\n",
      "['יום נתמקד בנושא הזה חזל תיקנו שבן שיירש נכסים מאב שלו אפילו שהוא כבר נחשב גדול כלומר הוא מעל שלושה ויש לו שתי שערות הוא יכול למכור את הנכסים עד שהוא מגיע לגיל מ']\n",
      "Imvladikon\n",
      "['התמד בנושא זה לתקנו שבן שנכסי מעשר גדול כלומר מעלות ולא יכול למכור את נכסי עד שהוא מגיע']\n",
      "For Sample 4\n",
      "Bert\n",
      "['מסוים כמו שעוד רגע נראה מה הסברה בהמשך הגמרה אומרים שאני שבין שהוא פחות משמונה עשרה או עשרים הוא עד לא מספיק בגר בשביל להתעסק עם כסף ואנו לא רוצים שהויי']\n",
      "Imvladikon\n",
      "['מסוים כמו שעוד רגע נראה מורה במשך מר אומרים שני שבן שהוא פחות משמונה ולא מספיק וגבי כסף אנחנו לא רוצים שוי']\n",
      "For Sample 5\n",
      "Bert\n",
      "['שישתויות מישהו יציע לו כסף ויתלהב מעצם זה הוא מקבל כסף ומקור בזול מדי אז לכן הוא לא יכול למקור עד שהוא מגיע לגיל מסוים והבישתיסרות שזה מר ב']\n",
      "Imvladikon\n",
      "['מישהו יצילו כשהוא הלב משהו קבל כסף ימכור בזול מדי אז לכן הוא לא יכול למכור עד שהוא הגיע לגיל מסוים ושתי שערות שזה מראה על']\n",
      "For Sample 6\n",
      "Bert\n",
      "['רות לאיזה גיל בזה יש מחלוקת מה רב נחמן אמר רבא אומר בן שמונה עשרה ורבהונה אומר בן עשרים כשב מקשר היזהר על בונה שאמר בן עשרים אותו מקרה שקרה בבני']\n",
      "Imvladikon\n",
      "['לזה ג זה מחלוקת רבנחמןאמר בין רבונו עכשיו מקשה בזר על רבו ב אותו מקרה שקרא בני']\n",
      "For Sample 7\n",
      "Bert\n",
      "['רק שראינו בדף הקודם והזכרנו אכשיו שמה יורשים טענו שהוא היה קטן כלומר הוא היה אמנם בין עשרים או בן שמונה עשרה אבל הא עוד לאהבי שתיסרותואז הצד השני אמר שבו']\n",
      "Imvladikon\n",
      "['שראינו בדף הקודם והזכרנו עכשיו היורשים תנו והיה הקטן אינם בן עשר בן שנה עד לבית רות ואז הצד השני']\n",
      "For Sample 8\n",
      "Bert\n",
      "['נפתח תקבר ונבדוק ורביאקיבה אמר שאין עם לפתוח זה לא בדיקה ילה אבל אמר רביזיירהתועלת מלפתוח תקבר ולבדוק אם יש לו שתי סערת זה רק אם אנחי צריך להיות בין שמו']\n",
      "Imvladikon\n",
      "['או נפתח את הקבר ונבדוק רבי במשנה לפתוח זה לא בדיקה אבל אומר בזרוע לפתוח את הקבר ודוקא של שתי שערות זרק יחשך בית']\n",
      "For Sample 9\n",
      "Bert\n",
      "['ה עשרה ושתיסרות אבל אם הגיל הוא גיל עשרים אז מגיל עשרים שתי סערות כבר לא משנים כי הרי יש משנה בנידה שאומרת שמי שלא הביא שתי צרות עד גיל עשרים זה אומר שהוא צר']\n",
      "Imvladikon\n",
      "['הא ותשעת אבל אם מגורים שתי שערות כבר לא משנים כי הרי יש משנה בנישאות שלא שתי שערות ים זה אומר שהוא עת']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sample = chunks[i]\n",
    "    sf.write(f\"samples/bert_test_{i}.wav\", sample, 16000)\n",
    "    print(f\"For Sample {i}\")\n",
    "    print(\"Bert\")\n",
    "    print(wav2vec2BertLm.get_prediction(sample))\n",
    "    print(\"Imvladikon\")\n",
    "    print(wav2vec_he_lm.get_prediction(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
