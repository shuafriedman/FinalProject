{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from dataclasses import dataclass, field\n",
    "import torch\n",
    "\n",
    "dataset = load_from_disk(\"/teamspace/studios/this_studio/datasets/fleurs-filtered-proc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2BertProcessor, Wav2Vec2BertForCTC\n",
    "processor = Wav2Vec2BertProcessor.from_pretrained(\"/teamspace/studios/this_studio/models/facebook/w2v-bert-2.0-finetuned\")\n",
    "model= Wav2Vec2BertForCTC.from_pretrained(\"/teamspace/studios/this_studio/models/facebook/w2v-bert-2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator, DistributedType\n",
    "accelerator = Accelerator(mixed_precision=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import DataCollatorCTCWithPadding\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, input_key='input_features', padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(dataset['train'], batch_size=8, collate_fn=data_collator),\n",
    "    'test': DataLoader(dataset['test'], batch_size=8, collate_fn=data_collator)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Batch 76:\n",
      "Key: input_features\n",
      "  Type: torch.float32\n",
      "  Shape: torch.Size([8, 392, 160])\n",
      "  No NaNs or Infs detected.\n",
      "Key: attention_mask\n",
      "  Type: torch.int32\n",
      "  Shape: torch.Size([8, 392])\n",
      "  No NaNs or Infs detected.\n",
      "Key: labels\n",
      "  Type: torch.int64\n",
      "  Shape: torch.Size([8, 69])\n",
      "  No NaNs or Infs detected.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assume dataloaders is a dictionary with 'train' key for train_dataloader\n",
    "dataloader = dataloaders[\"train\"]\n",
    "batch_size = 8\n",
    "\n",
    "# Function to check the data types of a batch\n",
    "\n",
    "def get_batch(data_loader, batch_idx):\n",
    "    \"\"\"\n",
    "    Fetches a specific batch by index from a DataLoader using an iterator.\n",
    "    \n",
    "    Args:\n",
    "    data_loader (torch.utils.data.DataLoader): The DataLoader.\n",
    "    batch_idx (int): Index of the batch to fetch.\n",
    "    \n",
    "    Returns:\n",
    "    Any: The batch at the specified index.\n",
    "    \"\"\"\n",
    "    batch_iter = iter(data_loader)\n",
    "    for _ in range(batch_idx):\n",
    "        batch = next(batch_iter)\n",
    "    return batch\n",
    "\n",
    "def check_batch(batch):\n",
    "    \"\"\"\n",
    "    Check the data types and other properties of each element in the batch.\n",
    "    Handles dictionary-based batch structures.\n",
    "    \n",
    "    Args:\n",
    "    batch (dict): A batch that may contain various elements keyed by descriptive names.\n",
    "    \"\"\"\n",
    "    for key, item in batch.items():\n",
    "        print(f\"Key: {key}\")\n",
    "        print(\"  Type:\", item.dtype)\n",
    "        print(\"  Shape:\", item.shape)\n",
    "        if torch.isnan(item).any() or torch.isinf(item).any():\n",
    "            print(\"  Contains NaNs or Infs.\")\n",
    "        else:\n",
    "            print(\"  No NaNs or Infs detected.\")\n",
    "\n",
    "\n",
    "def compare_batches(data_loader):\n",
    "    \"\"\"\n",
    "    Compares the 158th and 159th batch of the DataLoader.\n",
    "    \n",
    "    Args:\n",
    "    data_loader (torch.utils.data.DataLoader): The DataLoader to inspect.\n",
    "    \"\"\"\n",
    "    batch_156 = get_batch(data_loader, 75)\n",
    "    # batch_157 = get_batch(data_loader, 76)\n",
    "    # batch_158 = get_batch(data_loader, 77)\n",
    "    # batch_159 = get_batch(data_loader, 78)\n",
    "    \n",
    "    print(\"Checking Batch 76:\")\n",
    "    check_batch(batch_156)\n",
    "\n",
    "    # print(\"Checking Batch 76:\")\n",
    "    # check_batch(batch_157)\n",
    "    \n",
    "    # print(\"Checking Batch 77:\")\n",
    "    # check_batch(batch_158)\n",
    "    \n",
    "    # print(\"\\nChecking Batch 78:\")\n",
    "    # check_batch(batch_159)\n",
    "\n",
    "# Example usage (you'll need to replace `your_data_loader` with your actual DataLoader)\n",
    "# compare_batches(your_data_loader)\n",
    "\n",
    "\n",
    "compare_batches(dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_number = 78\n",
    "start_index = (batch_number - 1) * batch_size\n",
    "end_index = start_index + batch_size\n",
    "\n",
    "# Slice the dataset to get the 77th batch\n",
    "sub_dataset = dataset['train'].select(range(start_index, end_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "label:  31\n",
      "344\n",
      "label:  80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n",
      "label:  86\n",
      "326\n",
      "label:  74\n",
      "356\n",
      "label:  78\n",
      "278\n",
      "label:  56\n",
      "257\n",
      "label:  64\n",
      "197\n",
      "label:  47\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(len(sub_dataset[\"input_features\"][i]))\n",
    "    \n",
    "    print(\"label: \", len(sub_dataset[\"labels\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
