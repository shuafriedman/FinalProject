{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from dataclasses import dataclass, field\n",
    "import torch\n",
    "\n",
    "dataset = load_from_disk(\"/teamspace/studios/this_studio/FinalProject/wav2vec_finetune/wav2vec2bert/datasets/fleurs-filtered-proc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2BertProcessor\n",
    "processor = Wav2Vec2BertProcessor.from_pretrained(\"models/facebook/w2v-bert-2.0-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator, DistributedType\n",
    "accelerator = Accelerator(mixed_precision=\"no\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    def __init__(self, processor, accelerator, input_key='input_features', padding=True):\n",
    "        self.processor = processor\n",
    "        self.accelerator= accelerator\n",
    "        self.input_key = input_key\n",
    "        self.padding = padding\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        if self.input_key == 'input_features':\n",
    "            input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        elif self.input_key == 'input_values':\n",
    "            input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        # Determine pad_to_multiple_of based on accelerator's mixed precision\n",
    "        if self.accelerator.distributed_type == DistributedType.XLA:\n",
    "            max_length = 128\n",
    "        else:\n",
    "            max_length = None\n",
    "\n",
    "        if self.accelerator.mixed_precision == \"fp8\":\n",
    "            pad_to_multiple_of = 16\n",
    "        elif self.accelerator.mixed_precision != \"no\":\n",
    "            pad_to_multiple_of = 8\n",
    "        else:\n",
    "            pad_to_multiple_of = None\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=max_length,\n",
    "            pad_to_multiple_of=pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        labels_batch = self.processor.pad(\n",
    "            labels=label_features,\n",
    "            padding=self.padding,\n",
    "            max_length=max_length,\n",
    "            pad_to_multiple_of=pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, accelerator=accelerator, input_key='input_features', padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(dataset['train'], batch_size=4, collate_fn=data_collator),\n",
    "    'test': DataLoader(dataset['test'], batch_size=4, collate_fn=data_collator)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Batch 157:\n",
      "Key: input_features\n",
      "  Type: torch.float32\n",
      "  Shape: torch.Size([4, 398, 160])\n",
      "  No NaNs or Infs detected.\n",
      "Key: attention_mask\n",
      "  Type: torch.int32\n",
      "  Shape: torch.Size([4, 398])\n",
      "  No NaNs or Infs detected.\n",
      "Key: labels\n",
      "  Type: torch.int64\n",
      "  Shape: torch.Size([4, 108])\n",
      "  No NaNs or Infs detected.\n",
      "Checking Batch 158:\n",
      "Key: input_features\n",
      "  Type: torch.float32\n",
      "  Shape: torch.Size([4, 395, 160])\n",
      "  No NaNs or Infs detected.\n",
      "Key: attention_mask\n",
      "  Type: torch.int32\n",
      "  Shape: torch.Size([4, 395])\n",
      "  No NaNs or Infs detected.\n",
      "Key: labels\n",
      "  Type: torch.int64\n",
      "  Shape: torch.Size([4, 123])\n",
      "  No NaNs or Infs detected.\n",
      "\n",
      "Checking Batch 159:\n",
      "Key: input_features\n",
      "  Type: torch.float32\n",
      "  Shape: torch.Size([4, 386, 160])\n",
      "  No NaNs or Infs detected.\n",
      "Key: attention_mask\n",
      "  Type: torch.int32\n",
      "  Shape: torch.Size([4, 386])\n",
      "  No NaNs or Infs detected.\n",
      "Key: labels\n",
      "  Type: torch.int64\n",
      "  Shape: torch.Size([4, 101])\n",
      "  No NaNs or Infs detected.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assume dataloaders is a dictionary with 'train' key for train_dataloader\n",
    "dataloader = dataloaders[\"train\"]\n",
    "batch_size = 4\n",
    "\n",
    "# Function to check the data types of a batch\n",
    "\n",
    "def get_batch(data_loader, batch_idx):\n",
    "    \"\"\"\n",
    "    Fetches a specific batch by index from a DataLoader using an iterator.\n",
    "    \n",
    "    Args:\n",
    "    data_loader (torch.utils.data.DataLoader): The DataLoader.\n",
    "    batch_idx (int): Index of the batch to fetch.\n",
    "    \n",
    "    Returns:\n",
    "    Any: The batch at the specified index.\n",
    "    \"\"\"\n",
    "    batch_iter = iter(data_loader)\n",
    "    for _ in range(batch_idx):\n",
    "        batch = next(batch_iter)\n",
    "    return batch\n",
    "\n",
    "def check_batch(batch):\n",
    "    \"\"\"\n",
    "    Check the data types and other properties of each element in the batch.\n",
    "    Handles dictionary-based batch structures.\n",
    "    \n",
    "    Args:\n",
    "    batch (dict): A batch that may contain various elements keyed by descriptive names.\n",
    "    \"\"\"\n",
    "    for key, item in batch.items():\n",
    "        print(f\"Key: {key}\")\n",
    "        print(\"  Type:\", item.dtype)\n",
    "        print(\"  Shape:\", item.shape)\n",
    "        if torch.isnan(item).any() or torch.isinf(item).any():\n",
    "            print(\"  Contains NaNs or Infs.\")\n",
    "        else:\n",
    "            print(\"  No NaNs or Infs detected.\")\n",
    "\n",
    "\n",
    "def compare_batches(data_loader):\n",
    "    \"\"\"\n",
    "    Compares the 158th and 159th batch of the DataLoader.\n",
    "    \n",
    "    Args:\n",
    "    data_loader (torch.utils.data.DataLoader): The DataLoader to inspect.\n",
    "    \"\"\"\n",
    "    batch_157 = get_batch(data_loader, 157)\n",
    "    batch_158 = get_batch(data_loader, 158)\n",
    "    batch_159 = get_batch(data_loader, 159)\n",
    "    \n",
    "    print(\"Checking Batch 157:\")\n",
    "    check_batch(batch_157)\n",
    "    \n",
    "    print(\"Checking Batch 158:\")\n",
    "    check_batch(batch_158)\n",
    "    \n",
    "    print(\"\\nChecking Batch 159:\")\n",
    "    check_batch(batch_159)\n",
    "\n",
    "# Example usage (you'll need to replace `your_data_loader` with your actual DataLoader)\n",
    "# compare_batches(your_data_loader)\n",
    "\n",
    "\n",
    "compare_batches(dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
